{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC6AwHBb9p7g"
   },
   "source": [
    "#Analisis Data Prediksi Cuaca dengan Komputasi Paralel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JFBfIYE9qqe"
   },
   "source": [
    "**Pendahuluan**\n",
    "\n",
    "Prediksi cuaca melibatkan analisis data dalam jumlah besar, seperti suhu, kelembapan, tekanan udara, dan kecepatan angin. Analisis ini sering menggunakan model regresi atau pembelajaran mesin untuk memprediksi parameter cuaca di masa depan. Namun, proses pengolahan data tersebut membutuhkan waktu yang lama, terutama jika dilakukan secara serial. Oleh karena itu, pendekatan komputasi paralel, termasuk OpenMP, MPI, dan Spark, dapat digunakan untuk mempercepat proses ini.\n",
    "\n",
    "Tujuan eksperimen ini adalah membandingkan performa komputasi serial, paralel biasa, OpenMP, MPI, dan Spark dalam melakukan prediksi suhu menggunakan regresi linear sederhana pada dataset besar.\n",
    "\n",
    "**Dataset**\n",
    "Dataset cuaca yang digunakan adalah simulasi data suhu dengan parameter:\n",
    "\n",
    "Fitur: Waktu (jam), kelembapan, tekanan udara, kecepatan angin.\n",
    "\n",
    "Target: Suhu (dalam derajat Celcius).\n",
    "\n",
    "Dataset akan dihasilkan secara acak untuk keperluan eksperimen ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT3_SBvu_jG-"
   },
   "source": [
    "**1. Komputasi Serial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7S8XnVzj_mWv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komputasi serial selesai dalam waktu: 0.09 detik\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "\n",
    "# Generate synthetic weather data\n",
    "np.random.seed(42)\n",
    "n_samples = 10**6\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'hour': np.random.randint(0, 24, n_samples),\n",
    "    'humidity': np.random.uniform(30, 90, n_samples),\n",
    "    'pressure': np.random.uniform(1000, 1020, n_samples),\n",
    "    'wind_speed': np.random.uniform(0, 15, n_samples),\n",
    "    'temperature': np.random.uniform(15, 35, n_samples)\n",
    "})\n",
    "\n",
    "# Split features and target\n",
    "X = data[['hour', 'humidity', 'pressure', 'wind_speed']]\n",
    "y = data['temperature']\n",
    "\n",
    "# Komputasi serial\n",
    "start_time = time.time()\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "serial_time = time.time() - start_time\n",
    "\n",
    "print(f\"Komputasi serial selesai dalam waktu: {serial_time:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzh5foui9su8"
   },
   "source": [
    "**2. Komputasi Paralel Biasa**\n",
    "\n",
    "Menggunakan pustaka Joblib untuk melakukan paralelisme sederhana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_BZt5xbAFY8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komputasi paralel selesai dalam waktu: 2.12 detik\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Fungsi paralel untuk fitting model per partisi data\n",
    "def parallel_fit(partition):\n",
    "    model = LinearRegression()\n",
    "    model.fit(partition[\"X\"], partition[\"y\"])\n",
    "    return model\n",
    "\n",
    "# Membagi dataset menjadi partisi\n",
    "n_partitions = 4\n",
    "partitions = [\n",
    "    {\n",
    "        \"X\": X.iloc[i::n_partitions],\n",
    "        \"y\": y.iloc[i::n_partitions]\n",
    "    }\n",
    "    for i in range(n_partitions)\n",
    "]\n",
    "\n",
    "# Komputasi paralel\n",
    "start_time = time.time()\n",
    "models = Parallel(n_jobs=n_partitions)(delayed(parallel_fit)(partition) for partition in partitions)\n",
    "parallel_time = time.time() - start_time\n",
    "\n",
    "print(f\"Komputasi paralel selesai dalam waktu: {parallel_time:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey_yuA0S9tU4"
   },
   "source": [
    "**3.  Komputasi Paralel dengan OpenMP dan MPI**\n",
    "\n",
    "Pendekatan ini memerlukan implementasi di lingkungan HPC, namun untuk simulasi, kita dapat menggunakan pustaka Python seperti mpi4py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95_aE_JNArMm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpi4py in c:\\users\\62822\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqYJdLR2APVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dari semua proses dikumpulkan: 1\n",
      "Hasil prediksi contoh dari model pertama: [25.01486123 24.99178783 24.99404748 25.00312572 24.99505331]\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "# Membagi data berdasarkan rank\n",
    "chunk_size = n_samples // size\n",
    "start_idx = rank * chunk_size\n",
    "end_idx = (rank + 1) * chunk_size if rank != size - 1 else n_samples\n",
    "\n",
    "X_chunk = X.iloc[start_idx:end_idx]\n",
    "y_chunk = y.iloc[start_idx:end_idx]\n",
    "\n",
    "# Fitting model pada setiap proses\n",
    "local_model = LinearRegression()\n",
    "local_model.fit(X_chunk, y_chunk)\n",
    "\n",
    "# Mengumpulkan model di root process\n",
    "all_models = comm.gather(local_model, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"Model dari semua proses dikumpulkan: {len(all_models)}\")\n",
    "    # Menampilkan hasil prediksi dari model pertama sebagai contoh\n",
    "    if all_models:\n",
    "        sample_prediction = all_models[0].predict(X.iloc[:5])\n",
    "        print(f\"Hasil prediksi contoh dari model pertama: {sample_prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s3EIQ9h9tzy"
   },
   "source": [
    "**4. Komputasi Paralel dengan Spark**\n",
    "\n",
    "Menggunakan PySpark untuk menjalankan operasi secara terdistribusi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oo1hIAtr9hBo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menampilkan contoh hasil prediksi:\n",
      "+------------------+------------------+\n",
      "|       temperature|        prediction|\n",
      "+------------------+------------------+\n",
      "|34.993794858137235|24.987028192539597|\n",
      "| 16.24817060472536|24.992846640755342|\n",
      "|19.937212868780577| 24.99374138191184|\n",
      "|24.425807670965916| 24.99710255130901|\n",
      "| 18.73266074584903|24.995163216311543|\n",
      "+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Inisialisasi Spark\n",
    "spark = SparkSession.builder.appName(\"Weather Prediction\").getOrCreate()\n",
    "\n",
    "# Konversi DataFrame ke Spark DataFrame\n",
    "spark_df = spark.createDataFrame(data)\n",
    "\n",
    "# Menyusun fitur menjadi satu kolom\n",
    "feature_cols = ['hour', 'humidity', 'pressure', 'wind_speed']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "spark_df = assembler.transform(spark_df)\n",
    "\n",
    "# Membagi data menjadi training dan test\n",
    "train_df, test_df = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Membuat dan melatih model regresi linear\n",
    "lr = LinearRegression(featuresCol='features', labelCol='temperature')\n",
    "model = lr.fit(train_df)\n",
    "\n",
    "# Evaluasi model\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Menampilkan hasil prediksi pertama untuk memastikan hasilnya\n",
    "print(\"Menampilkan contoh hasil prediksi:\")\n",
    "predictions.select('temperature', 'prediction').show(5)\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10Aez1XW9mmr"
   },
   "source": [
    "# Tugas.\n",
    "\n",
    "Lakukan simulasi contoh kode diatas sebagai implementasi dari komputasi paralel. Setelah itu lakukan analisis hasil dari percobaan tersebut, selain melakukan analisis dan pembahasan hasil, lakukan pula analisis dan pembahasan dari kode program dalam melakukan komputasi paralel. Coba pula lakukan pada simulasi pada data yang lebih besar (bisa mencari pentunjuk di internet). Cari kelebihan dan kekurangan dari masing-masing metode dalam penerapan simulasi tersebut. Tuangkan dalam format draft artikel yang terdiri dari:\n",
    "1. Pendahuluan\n",
    "2. Penelitian terkait dan landasan teori\n",
    "3. Meodologi Penelitian\n",
    "4. Hasil dan Pembahasan\n",
    "5. Kesimpulan\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmGlqV2vUnwiIg/3s9FAsi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
